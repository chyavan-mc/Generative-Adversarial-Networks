{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow import nn\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from os.path import exists"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "ndata_train = x_train.shape[0]\n",
    "ndata_test = x_test.shape[0]\n",
    "\n",
    "plt.pcolor( x_train[np.random.randint(ndata_train),::-1,:] , cmap = 'gray' )\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "x_train = x_train.reshape((ndata_train,28,28,1))\n",
    "x_test = x_test.reshape((ndata_test,28,28,1))\n",
    "xshape = x_train.shape[1:]\n",
    "xshape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_shape = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 392)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               50304     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               12900     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                5184      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                3250      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                3264      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 80)                5200      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               8100      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 392)               50568     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 8)           0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 8)         584       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 16)        1168      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164,163\n",
      "Trainable params: 164,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = keras.Input(shape=xshape)\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128,activation='relu')(x)\n",
    "x = layers.Dense(100,activation='relu')(x)\n",
    "x = layers.Dense(80,activation='relu')(x)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "encoded = layers.Dense(embedding_shape,activation='sigmoid')(x)\n",
    "\n",
    "x = layers.Dense(64,activation='relu')(encoded)\n",
    "x = layers.Dense(80,activation='relu')(x)\n",
    "x = layers.Dense(100,activation='relu')(x)\n",
    "x = layers.Dense(128,activation='relu')(x)\n",
    "x = layers.Dense(392,activation='relu')(x)\n",
    "x = layers.Reshape((7, 7, 8))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "if not exists('./model_weights/autoencoder/autoencoder_model.index'):\n",
    "    print(\"Training model\")\n",
    "    ae_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        min_delta=0.0005,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    autoencoder.fit(x_train,x_train,epochs=50,validation_split=0.2,batch_size=256, verbose=1, shuffle=True, callbacks=[ae_callback])\n",
    "    autoencoder.save_weights('./model_weights/autoencoder/autoencoder_model')\n",
    "else:\n",
    "    print(\"Loading model\")\n",
    "    autoencoder.load_weights('./model_weights/autoencoder/autoencoder_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48494905, 0.13008761, 0.7595014 , 0.41827664, 0.36394754,\n",
       "        0.07493984, 0.57358116, 0.5252452 , 0.03026726, 0.3184195 ,\n",
       "        0.6637031 , 0.01709539, 0.5547777 , 0.75020397, 0.9287551 ,\n",
       "        0.69755435, 0.2973771 , 0.7089731 , 0.3653343 , 0.5817397 ,\n",
       "        0.07840388, 0.38368684, 0.23674218, 0.605418  , 0.4399961 ,\n",
       "        0.44474822, 0.38632795, 0.99180037, 0.04420195, 0.8405984 ,\n",
       "        0.6250735 , 0.50136644, 0.49827504, 0.18776414, 0.7011591 ,\n",
       "        0.4411143 , 0.8741153 , 0.5147026 , 0.19746642, 0.47177824,\n",
       "        0.02673137, 0.26059523, 0.63896245, 0.5796332 , 0.17804798,\n",
       "        0.9518764 , 0.55145735, 0.30916798, 0.27956167, 0.9988612 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = keras.Model(input_img, encoded)\n",
    "encoded_op = encoder.predict(x_test[idx:idx+1])\n",
    "display(y_test[idx])\n",
    "encoded_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1437e477970>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reprentn = encoded_op\n",
    "\n",
    "decoder = keras.Model(encoded, decoded)\n",
    "plt.imshow(\n",
    "    decoder(reprentn + 0.5*np.random.random()).numpy().reshape((28, 28))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               115300    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224,382\n",
      "Trainable params: 224,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ip_classifier = keras.Input(shape=xshape)\n",
    "\n",
    "x = layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\")(ip_classifier)\n",
    "x = layers.MaxPooling2D(pool_size=(3,3), strides=1)(x)\n",
    "x = layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(4,4), strides=2)(x)\n",
    "x = layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(4,4), strides=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100,activation='relu')(x)\n",
    "x = layers.Dense(80,activation='relu')(x)\n",
    "x = layers.Dense(60,activation='relu')(x)\n",
    "x = layers.Dense(40,activation='relu')(x)\n",
    "x = layers.Dense(20,activation='relu')(x)\n",
    "op_classifier = layers.Dense(10,activation='softmax')(x)\n",
    "\n",
    "classifier_model = keras.Model(ip_classifier, op_classifier)\n",
    "classifier_model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "if not exists('./model_weights/neural-net/classifier_model.index'):\n",
    "    print(\"Training model\")\n",
    "    cl_callback = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        min_delta=0.0002,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    classifier_model.fit(x_train,y_train,epochs=50,validation_split=0.2,batch_size=128, verbose=1, shuffle=True, callbacks=[cl_callback])\n",
    "    classifier_model.save_weights('./model_weights/neural-net/classifier_model')\n",
    "else:\n",
    "    print(\"Loading model\")\n",
    "    classifier_model.load_weights('./model_weights/neural-net/classifier_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "0.9913\n"
     ]
    }
   ],
   "source": [
    "pred_probs = classifier_model.predict(x_test)\n",
    "pred2 = np.argmax(pred_probs, axis=1)\n",
    "print(np.mean(pred2==y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder + Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 28, 28, 1)         164163    \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               115300    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 40)                2440      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 388,545\n",
      "Trainable params: 224,382\n",
      "Non-trainable params: 164,163\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.trainable = False\n",
    "\n",
    "ip_aeclassifier = keras.Input(shape=xshape)\n",
    "x = autoencoder(ip_aeclassifier, training=False)\n",
    "x = layers.Conv2D(filters=32,kernel_size=(3,3),padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(3,3), strides=1)(x)\n",
    "x = layers.Conv2D(filters=64,kernel_size=(3,3), activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(4,4), strides=2)(x)\n",
    "x = layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu')(x)\n",
    "x = layers.MaxPooling2D(pool_size=(4,4), strides=2)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(100,activation='relu')(x)\n",
    "x = layers.Dense(80,activation='relu')(x)\n",
    "x = layers.Dense(60,activation='relu')(x)\n",
    "x = layers.Dense(40,activation='relu')(x)\n",
    "x = layers.Dense(20,activation='relu')(x)\n",
    "op_aeclassifier = layers.Dense(10,activation='softmax')(x)\n",
    "\n",
    "aeclassifier_model = keras.Model(ip_aeclassifier, op_aeclassifier)\n",
    "aeclassifier_model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "aeclassifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    }
   ],
   "source": [
    "if not exists('./model_weights/ae-nn/aeclassifier_model.index'):\n",
    "    print(\"Training model\")\n",
    "    cl_callback = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        min_delta=0.0002,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    aeclassifier_model.fit(x_train,y_train,epochs=50,validation_split=0.2,batch_size=128, verbose=1, shuffle=True, callbacks=[cl_callback])\n",
    "    aeclassifier_model.save_weights('./model_weights/ae-nn/aeclassifier_model')\n",
    "else:\n",
    "    print(\"Loading model\")\n",
    "    aeclassifier_model.load_weights('./model_weights/ae-nn/aeclassifier_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "0.9606\n"
     ]
    }
   ],
   "source": [
    "pred_probs = aeclassifier_model.predict(x_test)\n",
    "pred2 = np.argmax(pred_probs, axis=1)\n",
    "print(np.mean(pred2==y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/generative/adversarial_fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import GradientTape, sign\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "def get_adversarial_label(prediction, input_label):\n",
    "    pred_copy = prediction.numpy()[0]\n",
    "    pred_copy[input_label] = -1\n",
    "    return np.argmax(pred_copy)\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label, directed=False):\n",
    "    # x -> [x]\n",
    "    input_image = tf.convert_to_tensor(input_image[None, ...], dtype=None, dtype_hint=None, name=None)\n",
    "\n",
    "    # Gradient\n",
    "    with GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = classifier_model(input_image)\n",
    "        if directed:\n",
    "            input_label = get_adversarial_label(prediction, input_label)\n",
    "        # y1 -> [[0,1,0,...0]]\n",
    "        input_label = tf.one_hot(input_label, 10)\n",
    "        input_label = tf.reshape(input_label, (1, 10))\n",
    "        loss = loss_object(input_label, prediction)\n",
    "\n",
    "    # Get the gradients of the loss w.r.t to the input image.\n",
    "    direction = -1 if directed else 1\n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    signed_grad = (direction*gradient)[0]\n",
    "    return ((signed_grad - signed_grad.numpy().mean())/(signed_grad.numpy().max() - signed_grad.numpy().min() + 10**(-10)))\n",
    "\n",
    "def get_adversarial_image(input_image, input_label, epsilon=0.01, directed=False):\n",
    "    noise = create_adversarial_pattern(input_image, input_label, directed=directed)\n",
    "    adv_x = input_image + epsilon*noise\n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "    return adv_x.numpy(), noise.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.840000e+02\n",
       "mean     3.229124e-08\n",
       "std      7.628558e-07\n",
       "min     -4.744475e-06\n",
       "25%     -3.638284e-08\n",
       "50%      0.000000e+00\n",
       "75%      6.488976e-08\n",
       "max      7.733064e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_numb = np.random.randint(y_test.shape[0])\n",
    "test_label = y_test[rnd_numb]\n",
    "test_image = x_test[rnd_numb]\n",
    "\n",
    "grad = create_adversarial_pattern(test_image, test_label)\n",
    "import pandas as pd\n",
    "pd.Series(grad.numpy().reshape((28*28,))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_adversarial_attack(input_image, input_label, epsilon=0.01, directed=False):\n",
    "    adv_img, noise = get_adversarial_image(input_image, input_label, epsilon=epsilon, directed=directed)\n",
    "\n",
    "    actual_label = input_label\n",
    "\n",
    "    # Neural network prediction of the original image\n",
    "    pred = classifier_model(input_image[None, ...]).numpy().reshape((10,))\n",
    "    original_prediction_conf = pred.max().round(5)\n",
    "    original_prediction = pred.argmax()\n",
    "\n",
    "    # Neural network prediction of the adversarial image\n",
    "    adv_x = adv_img.reshape((1,*adv_img.shape))\n",
    "    pred = classifier_model(adv_x).numpy().reshape((10,))\n",
    "    adv_prediction_conf = pred.max().round(5)\n",
    "    adv_prediction = pred.argmax()\n",
    "\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(1, 3)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(18)\n",
    "\n",
    "    print(f\"Actual Label of the Image: {actual_label}\")\n",
    "    \n",
    "    ax0.pcolor(input_image.reshape((28,28))[::-1], cmap='gray')\n",
    "    ax0.axis('off')\n",
    "    ax0.set_title(f\"Original Image\\nPrediction: {original_prediction}\\nConfidence of prediction: {original_prediction_conf}\")\n",
    "\n",
    "    ax1.pcolor(noise.reshape((28,28))[::-1], cmap='gray')\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title(\"Perturbations being added\")\n",
    "\n",
    "    ax2.pcolor(adv_img.reshape((28,28))[::-1], cmap='gray')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(f\"Adversarial Image\\nPrediction: {adv_prediction}\\nConfidence of prediction: {adv_prediction_conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_numb = np.random.randint(y_test.shape[0])\n",
    "test_label = y_test[rnd_numb]\n",
    "test_image = x_test[rnd_numb]\n",
    "\n",
    "demo_adversarial_attack(test_image, test_label, epsilon=0.1, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adversarial_labels(input_images, input_labels, epsilon=0.01, directed=False):\n",
    "    n_len = len(input_images)\n",
    "    ret_labels = np.zeros(n_len)\n",
    "    for i in range(n_len):\n",
    "        adv_img, _ = get_adversarial_image(input_images[i], input_labels[i], epsilon=epsilon, directed=directed)\n",
    "        # if i%1000 == 13:\n",
    "        #     plt.pcolor(adv_img.reshape((28,28))[::-1], cmap='gray')\n",
    "        #     plt.show()\n",
    "        adv_x = adv_img.reshape((1,*adv_img.shape))\n",
    "        pred = classifier_model(adv_x).numpy().reshape((10,))\n",
    "        ret_labels[i] = pred.argmax()\n",
    "    return ret_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_labels = predict_adversarial_labels(x_test, y_test, epsilon=0.9, directed=False)\n",
    "print(np.mean(adversarial_labels==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeclassifier_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
